import tensorflow as tf
from tensorflow.keras import layers, models

# Load MNIST dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0  # normalize


print(x_train.shape)
print(x_test.shape)


# Build FCNN model
# sequential is used for stack one after another 
fcnn_model = models.Sequential([
    # input layer
    layers.Flatten(input_shape=(28,28)), # flatten isused to multi dimensinal to 1d

    #hidden layer 1
    layers.Dense(256, activation='relu'),# it lears the pattern 
    layers.Dropout(0.2),  # reduces overfitting by ignoring some neurons 

    #hidden layer 2
    layers.Dense(128, activation='relu'),# refines the pattern
    layers.Dropout(0.2),  # reduces overfitting by ignoring some neurons 

    # output layer for binary classification softmax is used
    layers.Dense(10, activation='softmax') # give probality of output
])

# Compile

fcnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                   loss='sparse_categorical_crossentropy', # for multi class categories data sparse_categorical_crossentropyloss function used
                   metrics=['accuracy'])

# Train
history_fcnn = fcnn_model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)

# Evaluate
train_loss, train_acc = fcnn_model.evaluate(x_train, y_train)
test_loss, test_acc = fcnn_model.evaluate(x_test, y_test)
print("FCNN Training Accuracy:", round(train_acc,4))
print("FCNN Test Accuracy:", round(test_acc,4))


from google.colab import files  # for Colab
from tensorflow.keras.preprocessing import image
import numpy as np


uploaded = files.upload()  # this will open a file chooser
img_path = list(uploaded.keys())[0]  # get the uploaded filename


# Load and resize to 28x28 grayscale
img = image.load_img(img_path, target_size=(28,28), color_mode='grayscale')

# Convert to array
img_array = image.img_to_array(img)

# Normalize
img_array = img_array / 255.0

# Add batch dimension
img_array = np.expand_dims(img_array, axis=0)  # shape (1,28,28,1) for CNN
prediction = fcnn_model.predict(img_array)
predicted_class = np.argmax(prediction)
print("Predicted digit:", predicted_class)


# Build CNN
cnn_model = models.Sequential([
    #input layer 
    layers.Reshape((28,28,1), input_shape=(28,28)),# to convert 2d image 28x28 into 28 height,28 width,1 channel black 
    
    layers.Conv2D(32, 3, activation='relu'), # 32filters and 3 kernal 3x3 matrix type
    layers.MaxPooling2D(2),# to get maximum value in the filter
    layers.Conv2D(64, 3, activation='relu'), # 64filters and 3 kernal 3x3 matrix type
    layers.MaxPooling2D(2),
    layers.Flatten(),
    layers.Dense(128, activation='relu'), # 128 filters and 3 kernal 3x3 matrix type
    layers.Dropout(0.3),#reduce overfit

    # output layer
    layers.Dense(10, activation='softmax')
])

# Compile
cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

# Train
history_cnn = cnn_model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.1)

# Evaluate
train_loss, train_acc = cnn_model.evaluate(x_train, y_train)
test_loss, test_acc = cnn_model.evaluate(x_test, y_test)
print("CNN Training Accuracy:", round(train_acc,4))
print("CNN Test Accuracy:", round(test_acc,4))


img = image.load_img(img_path, target_size=(28,28), color_mode='grayscale')
img_array = image.img_to_array(img)
img_array = img_array / 255.0

img_cnn = np.expand_dims(img_array, axis=0)  # shape (1,28,28,1)
prediction_cnn = cnn_model.predict(img_cnn)
predicted_class_cnn = np.argmax(prediction_cnn)
print("CNN Predicted Digit:", predicted_class_cnn)
fo rthis code
